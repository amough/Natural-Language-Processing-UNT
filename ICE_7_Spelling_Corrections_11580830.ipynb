{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBgH0Dc08SeX"
      },
      "source": [
        "# ICE - 7: Spelling Correction\n",
        "**Instructions**:\n",
        "1. Wherever you are asked to code, insert a text block below your code block and explain what you have coded as per your own understanding.\n",
        "2. If the code is provided by us, execute it, and add below a text block and provide your explanation in your own words.\n",
        "3. Submit both the .ipynb and pdf files to canvas.\n",
        "4. **The similarity score should be less than 15%.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1 (5 points)\n",
        "\n",
        "Explain the steps in \"non-word\" spelling error detection algorithm. Your answer needs to explain what the algorithm does in your own words."
      ],
      "metadata": {
        "id": "tWNbAhkGWFsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "***\n",
        "For \"non-word\" spelling error detection we compare the word with all the words present in the Dictionary. If the word is not present in Dictionary, we assume that we have \"non-word\" spelling error. For this the larger the Dictionary, our algortihtm will work better."
      ],
      "metadata": {
        "id": "iU1frGmBWbBa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAYfpbp-9lMV"
      },
      "source": [
        "# Task 2 (20 points)\n",
        "Use the follwing tutorial to implement spelling checking using Textblob. In the link provided below, \"text.txt\" contains a paragraph from an English novel. You can either implement the same data set by finding it online, or you can work on your own dataset.\n",
        "<br><br>**Do not forget to add spelling mistake words, as shown in the tutorial provided below**\n",
        "\n",
        "https://stackabuse.com/spelling-correction-in-python-with-textblob/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbTX_izw-PG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7165f517-6b7d-4fa2-b817-e6ed8ec298cf"
      },
      "source": [
        "pip install textblob\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#You can use this to upload your \"corpus.txt\" into google colab.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "Fu58t0c5d30u",
        "outputId": "d2158002-31a2-448a-be01-cc24d6bcba42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4a6cf193-25c1-4fdc-9e8e-1cfb29db33f0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4a6cf193-25c1-4fdc-9e8e-1cfb29db33f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving text.txt to text.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text.txt': b'As far as I am abl to judg, after long attnding to the sbject, the condiions of lfe apear to act in two ways\\xe2\\x80\\x94directly on the whle organsaton or on certin parts alne and indirectly by afcting the reproducte sstem. Wit respct to te dirct action, we mst bea in mid tht in every cse, as Profesor Weismann hs latly insistd, and as I have inidently shwn in my wrk on \"Variatin undr Domesticcation,\" thcere arae two factrs: namly, the natre of the orgnism and the natture of the condiions. The frmer sems to be much th mre importannt; foor nealy siimilar variations sometimes aris under, as far as we cn juddge, disimilar conditios; annd, on te oter hannd, disssimilar variatioons arise undder conditions which aappear to be nnearly uniiform. The efffects on tthe offspring arre ieither definnite or in definite. They maay be considdered as definnite whhen allc or neearly all thhe ofefspring off inadividuals exnposed tco ceertain conditionas duriing seveal ggenerations aree moodified in te saame maner.\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "with open(\"text.txt\", \"r\") as f:        # Opening the test file with the intention to read\n",
        "    text = f.read()                     # Reading the file\n",
        "    textBlb = TextBlob(text)            # Making our first textblob\n",
        "    textCorrected = textBlb.correct()   # Correcting the text\n",
        "    print(textCorrected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc_d2N9Qej4j",
        "outputId": "92e41bb6-7de2-45a6-df18-ba762993b238"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is far as I am all to judge, after long attending to the subject, the conditions of life appear to act in two ways—directly on the while organisation or on certain parts alone and indirectly by acting the reproduce system. It respect to te direct action, we must be in mid the in every case, as Professor Weismann he lately insisted, and as I have evidently shown in my work on \"Variation under Domesticcation,\" there are two facts: namely, the nature of the organism and the nature of the conditions. The former seems to be much th are important; for nearly similar variations sometimes arms under, as far as we in judge, similar condition; and, on te other hand, disssimilar variations arise under conditions which appear to be nearly uniform. The effects on the offspring are either definite or in definite. They may be considered as definite when all or nearly all the offspring off individuals exposed to certain conditions during several generations are modified in te same manner.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# A function that compares two texts and returns \n",
        "# the number of matches and differences\n",
        "def compare(text1, text2):  \n",
        "    l1 = text1.split()\n",
        "    l2 = text2.split()\n",
        "    good = 0\n",
        "    bad = 0\n",
        "    for i in range(0, len(l1)):\n",
        "        if l1[i] != l2[i]:\n",
        "            bad += 1\n",
        "        else:\n",
        "            good += 1\n",
        "    return (good, bad)\n",
        "\n",
        "# Helper function to calculate the percentage of misspelled words\n",
        "def percentageOfBad(x):\n",
        "    return (x[1] / (x[0] + x[1])) * 100"
      ],
      "metadata": {
        "id": "yRl-Lt1MXTWT"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''with open(\"test.txt.rtf\", \"r\") as f1: # test.txt contains the same typo-filled text from the last example \n",
        "  t1 = f1.read\n",
        "\n",
        "with open(\"original.txt.rtf\", \"r\") as f2: # original.txt contains the text from the actual book \n",
        "  t2 = f2.read()\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "with open(\"test.txt\", \"r\") as f: '''       # Opening the test file with the intention to read\n",
        "    #text = f.read()                     # Reading the file\n",
        "\n",
        "t1=\"To Sherlock Holmes she is always the womn. I have seldem heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirvbly balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirtble things for the observer--excellent for drawing the veil from men's motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt opon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Atler, of dubious and questionable memory.\"\n",
        "t2=\"To Sherlock Holmes she is always the woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirable things for the observer--excellent for drawing the veil from men's motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\"\n",
        "textBlb = TextBlob(t1)            # Making our first textblob\n",
        "t3 = textBlb.correct()\n",
        "\n",
        "mistakesCompOriginal = compare(t1, t2)\n",
        "originalCompCorrected = compare(t2, t3)\n",
        "mistakesCompCorrected = compare(t1, t3)\n",
        "\n",
        "print(\"Mistakes compared to original \", mistakesCompOriginal)\n",
        "print(\"Original compared to corrected \", originalCompCorrected)\n",
        "print(\"Mistakes compared to corrected \", mistakesCompCorrected, \"\\n\")\n",
        "\n",
        "print(\"Percentage of mistakes in the test: \", percentageOfBad(mistakesCompOriginal), \"%\")\n",
        "print(\"Percentage of mistakes in the corrected: \", percentageOfBad(originalCompCorrected), \"%\")\n",
        "print(\"Percentage of fixed mistakes: \", percentageOfBad(mistakesCompCorrected), \"%\", \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yblZJJi7XpiR",
        "outputId": "c85ef893-d30d-46ad-d2ba-577ca3d5ebb7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistakes compared to original  (200, 6)\n",
            "Original compared to corrected  (203, 3)\n",
            "Mistakes compared to corrected  (199, 7) \n",
            "\n",
            "Percentage of mistakes in the test:  2.912621359223301 %\n",
            "Percentage of mistakes in the corrected:  1.4563106796116505 %\n",
            "Percentage of fixed mistakes:  3.3980582524271843 % \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3 (5 points)\n",
        "What are the different kinds of spelling errors? Given 5 examples for each case. Also suggest a method/algorithm name to rectify each type of error."
      ],
      "metadata": {
        "id": "XUVD17JfblTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "*** \n",
        "The types of spelling errors are:\n",
        "1.Non-Words Errors.\n",
        "eg. cty-city, diferent-different, cowby-cowboy, handsme-handsome, garbege-garbage\n",
        "2.Real-Word Errors.\n",
        "2.A.Typographical errors\n",
        "eg.three-there, best-rest, tree-free, three-there, car-bar\n",
        "2.B.Cognitive Erros(Homophones)\n",
        "eg.weak-week, peace-piece, two-too, there-their, feat-feet."
      ],
      "metadata": {
        "id": "nHospSnubqjk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MXH3VV28eOj"
      },
      "source": [
        "# Task 4 (20 points)\n",
        "\n",
        "In this task, you will be building your own word-suggestion algorithm. Given an English word as input and a corpus, return the 3 nearest words **\"other than itself\"**, that will serve as suggestions to the input word. The input word must have spelling mistakes.\n",
        "\n",
        "**Example:**\n",
        "<br>**Corpus:** \"a an word doing what how ML is are your you who when am NLP\"\n",
        "<br>**Input word:** \"aze\"\n",
        "<br>**Your ouput should be:** [\"am\",\"are\",\"an\"]\n",
        "<br><br>**Note:**The output list can be in any order.\n",
        "Show your outputs for **5 different inputs**.\n",
        "<br>**Hint: Need not implement a complex NLP model. Think how Minimum Edit Distance algorithm can help.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def editDistance(str1, str2, m, n):\n",
        " \n",
        "    # If first string is empty, the only option is to\n",
        "    # insert all characters of second string into first\n",
        "    if m == 0:\n",
        "        return n\n",
        " \n",
        "    # If second string is empty, the only option is to\n",
        "    # remove all characters of first string\n",
        "    if n == 0:\n",
        "        return m\n",
        " \n",
        "    # If last characters of two strings are same, nothing\n",
        "    # much to do. Ignore last characters and get count for\n",
        "    # remaining strings.\n",
        "    if str1[m-1] == str2[n-1]:\n",
        "        return editDistance(str1, str2, m-1, n-1)\n",
        " \n",
        "    # If last characters are not same, consider all three\n",
        "    # operations on last character of first string, recursively\n",
        "    # compute minimum cost for all three operations and take\n",
        "    # minimum of three values.\n",
        "    return 1 + min(editDistance(str1, str2, m, n-1),    # Insert\n",
        "                   editDistance(str1, str2, m-1, n),    # Remove\n",
        "                   editDistance(str1, str2, m-1, n-1)    # Replace\n",
        "                   )\n",
        " \n",
        " \n",
        "# Driver code\n",
        "#str1 = \"thought\"\n",
        "#str2 = \"thinking\"\n",
        "#print (editDistance(str1, str2, len(str1), len(str2)))"
      ],
      "metadata": {
        "id": "aN6f_o0mF0ih"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVQ7Td-c-P-W"
      },
      "source": [
        "from numpy.core.fromnumeric import sort\n",
        "corpus=\"There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.\"\n",
        "words=[]\n",
        "for i, w in enumerate(corpus.split(\" \")):\n",
        "    words.append(w)\n",
        "dist = {}\n",
        "def three_Suggestions(word):\n",
        "  #Your code here\n",
        "  for item in words:\n",
        "    dist[item] = editDistance(item, word, len(item), len(word))\n",
        "  list = sorted(dist.items(), key=lambda x:x[1])\n",
        "  sortdictionary = dict(list)\n",
        "  for i in list[0:3]:\n",
        "    print(i)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "three_Suggestions(\"avalable\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehQo344JHiR9",
        "outputId": "5db222de-c19a-4fe8-dff3-88c342602b39"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('available,', 2)\n",
            "('are', 6)\n",
            "('have', 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "three_Suggestions(\"ar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCUC5Sd4IX6f",
        "outputId": "ae442a53-b00f-4f05-9d55-c4774f6967f6"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('are', 1)\n",
            "('or', 1)\n",
            "('a', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "three_Suggestions(\"hav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAZmJ7E6IYFv",
        "outputId": "c675de02-edca-4f22-a613-33489958b985"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('have', 1)\n",
            "('a', 2)\n",
            "('as', 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "three_Suggestions(\"suferred\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhY9MU8-IYRe",
        "outputId": "8029781e-a79e-49a0-d28f-585f4e29395f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('suffered', 2)\n",
            "('sure', 4)\n",
            "('There', 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "three_Suggestions(\"ging\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N00-tZsBIYfg",
        "outputId": "5ca77a23-ede6-46a2-f913-f669a474493c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('going', 1)\n",
            "('in', 2)\n",
            "('many', 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orglcNDl8x6d"
      },
      "source": [
        "# Task 5 (20 points)\n",
        "### Implement Petr Norvig algorithm for spelling corrections. The turtorial is provided in the link below:\n",
        "\n",
        "https://norvig.com/spell-correct.html\n",
        "\n",
        "**Note:** For this task, the corpus will be \"corpus.txt\", provided in **assignments->ICE-7** in canvas. Replace \"big.txt\" in the tutorial to \"corpus.txt\". Upload it to your google colab/jupyter notebook and use it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#You can use this to upload your \"corpus.txt\" into google colab.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "d0UinpILyqwK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "caee9699-a96f-4bb4-e57c-6550cd7b0754"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6976fec9-66c8-4766-b2ff-e91bc359fd9f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6976fec9-66c8-4766-b2ff-e91bc359fd9f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving corpus.txt to corpus.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'corpus.txt': b'To Sherlock Holmes she is always the woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirable things for the observer--excellent for drawing the veil from men\\'s motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\\r\\n\\r\\nI had seen little of Holmes lately. My marriage had drifted us away from each other. My own complete happiness, and the home-centred interests which rise up around the man who first finds himself master of his own establishment, were sufficient to absorb all my attention, while Holmes, who loathed every form of society with his whole Bohemian soul, remained in our lodgings in Baker Street, buried among his old books, and alternating from week to week between cocaine and ambition, the drowsiness of the drug, and the fierce energy of his own keen nature. He was still, as ever, deeply attracted by the study of crime, and occupied his immense faculties and extraordinary powers of observation in following out those clues, and clearing up those mysteries which had been abandoned as hopeless by the official police. From time to time I heard some vague account of his doings: of his summons to Odessa in the case of the Trepoff murder, of his clearing up of the singular tragedy of the Atkinson brothers at Trincomalee, and finally of the mission which he had accomplished so delicately and successfully for the reigning family of Holland. Beyond these signs of his activity, however, which I merely shared with all the readers of the daily press, I knew little of my former friend and companion.\\r\\n\\r\\nOne night--it was on the twentieth of March, 1888--I was returning from a journey to a patient (for I had now returned to civil practice), when my way led me through Baker Street. As I passed the well-remembered door, which must always be associated in my mind with my wooing, and with the dark incidents of the Study in Scarlet, I was seized with a keen desire to see Holmes again, and to know how he was employing his extraordinary powers. His rooms were brilliantly lit, and, even as I looked up, I saw his tall, spare figure pass twice in a dark silhouette against the blind. He was pacing the room swiftly, eagerly, with his head sunk upon his chest and his hands clasped behind him. To me, who knew his every mood and habit, his attitude and manner told their own story. He was at work again. He had risen out of his drug-created dreams and was hot upon the scent of some new problem. I rang the bell and was shown up to the chamber which had formerly been in part my own.\\r\\n\\r\\nHis manner was not effusive. It seldom was; but he was glad, I think, to see me. With hardly a word spoken, but with a kindly eye, he waved me to an armchair, threw across his case of cigars, and indicated a spirit case and a gasogene in the corner. Then he stood before the fire and looked me over in his singular introspective fashion.\\r\\n\\r\\n\"Wedlock suits you,\" he remarked. \"I think, Watson, that you have put on seven and a half pounds since I saw you.\"\\r\\n\\r\\n\"Seven!\" I answered.\\r\\n\\r\\n\"Indeed, I should have thought a little more. Just a trifle more, I fancy, Watson. And in practice again, I observe. You did not tell me that you intended to go into harness.\"\\r\\n\\r\\n\"Then, how do you know?\"\\r\\n\\r\\n\"I see it, I deduce it. How do I know that you have been getting yourself very wet lately, and that you have a most clumsy and careless servant girl?\"\\r\\n\\r\\n\"My dear Holmes,\" said I, \"this is too much. You would certainly have been burned, had you lived a few centuries ago. It is true that I had a country walk on Thursday and came home in a dreadful mess, but as I have changed my clothes I can\\'t imagine how you deduce it. As to Mary Jane, she is incorrigible, and my wife has given her notice, but there, again, I fail to see how you work it out.\"\\r\\n\\r\\nHe chuckled to himself and rubbed his long, nervous hands together.\\r\\n\\r\\n\"It is simplicity itself,\" said he; \"my eyes tell me that on the inside of your left shoe, just where the firelight strikes it, the leather is scored by six almost parallel cuts. Obviously they have been caused by someone who has very carelessly scraped round the edges of the sole in order to remove crusted mud from it. Hence, you see, my double deduction that you had been out in vile weather, and that you had a particularly malignant boot-slitting specimen of the London slavey. As to your practice, if a gentleman walks into my rooms smelling of iodoform, with a black mark of nitrate of silver upon his right forefinger, and a bulge on the right side of his top-hat to show where he has secreted his stethoscope, I must be dull, indeed, if I do not pronounce him to be an active member of the medical profession.\"\\r\\n\\r\\nI could not help laughing at the ease with which he explained his process of deduction. \"When I hear you give your reasons,\" I remarked, \"the thing always appears to me to be so ridiculously simple that I could easily do it myself, though at each successive instance of your reasoning I am baffled until you explain your process. And yet I believe that my eyes are as good as yours.\"\\r\\n\\r\\n\"Quite so,\" he answered, lighting a cigarette, and throwing himself down into an armchair. \"You see, but you do not observe. The distinction is clear. For example, you have frequently seen the steps which lead up from the hall to this room.\"\\r\\n\\r\\n\"Frequently.\"\\r\\n\\r\\n\"How often?\"\\r\\n\\r\\n\"Well, some hundreds of times.\"\\r\\n\\r\\n\"Then how many are there?\"\\r\\n\\r\\n\"How many? I don\\'t know.\"\\r\\n\\r\\n\"Quite so! You have not observed. And yet you have seen. That is just my point. Now, I know that there are seventeen steps, because I have both seen and observed. By the way, since you are interested in these little problems, and since you are good enough to chronicle one or two of my trifling experiences, you may be interested in this.\" He threw over a sheet of thick, pink-tinted notepaper which had been lying open upon the table. \"It came by the last post,\" said he. \"Read it aloud.\"\\r\\n\\r\\nThe note was undated, and without either signature or address.\\r\\n\\r\\n\"There will call upon you to-night, at a quarter to eight o\\'clock,\" it said, \"a gentleman who desires to consult you upon a matter of the very deepest moment. Your recent services to one of the royal houses of Europe have shown that you are one who may safely be trusted with matters which are of an importance which can hardly be exaggerated. This account of you we have from all quarters received. Be in your chamber then at that hour, and do not take it amiss if your visitor wear a mask.\"\\r\\n\\r\\n\"This is indeed a mystery,\" I remarked. \"What do you imagine that it means?\"\\r\\n\\r\\n\"I have no data yet. It is a capital mistake to theorise before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts. But the note itself. What do you deduce from it?\"\\r\\n\\r\\nI carefully examined the writing, and the paper upon which it was written.\\r\\n\\r\\n\"The man who wrote it was presumably well to do,\" I remarked, endeavouring to imitate my companion\\'s processes. \"Such paper could not be bought under half a crown a packet. It is peculiarly strong and stiff.\"\\r\\n\\r\\n\"Peculiar--that is the very word,\" said Holmes. \"It is not an English paper at all. Hold it up to the light.\"\\r\\n\\r\\nI did so, and saw a large \"E\" with a small \"g,\" a \"P,\" and a large \"G\" with a small \"t\" woven into the texture of the paper.\\r\\n\\r\\n\"What do you make of that?\" asked Holmes.\\r\\n\\r\\n\"The name of the maker, no doubt; or his monogram, rather.\"\\r\\n\\r\\n\"Not at all. The \\'G\\' with the small \\'t\\' stands for \\'Gesellschaft,\\' which is the German for \\'Company.\\' It is a customary contraction like our \\'Co.\\' \\'P,\\' of course, stands for \\'Papier.\\' Now for the \\'Eg.\\' Let us glance at our Continental Gazetteer.\" He took down a heavy brown volume from his shelves. \"Eglow, Eglonitz--here we are, Egria. It is in a German-speaking country--in Bohemia, not far from Carlsbad. \\'Remarkable as being the scene of the death of Wallenstein, and for its numerous glass-factories and paper-mills.\\' Ha, ha, my boy, what do you make of that?\" His eyes sparkled, and he sent up a great blue triumphant cloud from his cigarette.\\r\\n\\r\\n\"The paper was made in Bohemia,\" I said.\\r\\n\\r\\n\"Precisely. And the man who wrote the note is a German. Do you note the peculiar construction of the sentence--\\'This account of you we have from all quarters received.\\' A Frenchman or Russian could not have written that. It is the German who is so uncourteous to his verbs. It only remains, therefore, to discover what is wanted by this German who writes upon Bohemian paper and prefers wearing a mask to showing his face. And here he comes, if I am not mistaken, to resolve all our doubts.\"\\r\\n\\r\\nAs he spoke there was the sharp sound of horses\\' hoofs and grating wheels against the curb, followed by a sharp pull at the bell. Holmes whistled.\\r\\n\\r\\n\"A pair, by the sound,\" said he. \"Yes,\" he continued, glancing out of the window. \"A nice little brougham and a pair of beauties. A hundred and fifty guineas apiece. There\\'s money in this case, Watson, if there is nothing else.\"\\r\\n\\r\\n\"I think that I had better go, Holmes.\"\\r\\n\\r\\n\"Not a bit, Doctor. Stay where you are. I am lost without my Boswell. And this promises to be interesting. It would be a pity to miss it.\"\\r\\n\\r\\n\"But your client--\"\\r\\n\\r\\n\"Never mind him. I may want your help, and so may he. Here he comes. Sit down in that armchair, Doctor, and give us your best attention.\"\\r\\n\\r\\nA slow and heavy step, which had been heard upon the stairs and in the passage, paused immediately outside the door. Then there was a loud and authoritative tap.\\r\\n\\r\\n\"Come in!\" said Holmes.\\r\\n\\r\\nA man entered who could hardly have been less than six feet six inches in height, with the chest and limbs of a Hercules. His dress was rich with a richness which would, in England, be looked upon as akin to bad taste. Heavy bands of astrakhan were slashed across the sleeves and fronts of his double-breasted coat, while the deep blue cloak which was thrown over his shoulders was lined with flame-coloured silk and secured at the neck with a brooch which consisted of a single flaming beryl. Boots which extended halfway up his calves, and which were trimmed at the tops with rich brown fur, completed the impression of barbaric opulence which was suggested by his whole appearance. He carried a broad-brimmed hat in his hand, while he wore across the upper part of his face, extending down past the cheekbones, a black vizard mask, which he had apparently adjusted that very moment, for his hand was still raised to it as he entered. From the lower part of the face he appeared to be a man of strong character, with a thick, hanging lip, and a long, straight chin suggestive of resolution pushed to the length of obstinacy.\\r\\n\\r\\n\"You had my note?\" he asked with a deep harsh voice and a strongly marked German accent. \"I told you that I would call.\" He looked from one to the other of us, as if uncertain which to address.\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SMcdxJ7-RHc"
      },
      "source": [
        "#Your code here\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "WORDS = Counter(words(open('corpus.txt').read()))\n",
        "\n",
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correction('speking')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HF7Tprw2aJke",
        "outputId": "e8d6ef26-52e6-49a8-809f-06522b6b8512"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'speaking'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('sond')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j9gNVikWaVsD",
        "outputId": "a0678581-42f9-4b0d-ab36-df6fa2bd1244"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sound'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 6 (20 points)\n",
        "\n",
        "Show the outputs you have obtained by sending in 10 different words with spelling mistakes as input. Now build the Confusion matrix of the mis-spelled characters of your 10 inputs vs outputs.\n",
        "<br>**Note:You can refer to slide# 22 in Lecture-7 in Files on canvas**"
      ],
      "metadata": {
        "id": "NYzqIsY416B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Your code here\n",
        "correction('spaaking')"
      ],
      "metadata": {
        "id": "jHMrL81vsza5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d4efaa4-add6-4361-9100-a151eb5e936f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'speaking'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('soond')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eCNV5rLEbGkD",
        "outputId": "93fb4d2c-5dc2-4c19-8535-7a06c6a49dc1"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sound'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('corrse')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UxNSMbQcbJpa",
        "outputId": "5ff8b84d-af16-494f-ecfe-e4c93406f71c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'course'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('aacount')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lKKkMYa6bPIH",
        "outputId": "72a49c65-1e9b-4209-a6b0-10b344d4f7a2"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'account'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('imatate')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hed0TedSbUBT",
        "outputId": "5695526d-ae85-4028-f822-7894fdb70c68"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'imitate'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('cigrrette')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BsSPJV0abaEO",
        "outputId": "d67ab061-b7ee-462f-977a-d6e4671bf0eb"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cigarette'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('vritten')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qk5Ka0QGbjs0",
        "outputId": "27e48d5a-effe-452a-b6ef-9e33e11d7928"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'written'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('gentlaman')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CBqQ0l8Ibo3e",
        "outputId": "9d25649c-40c2-40bb-da93-d6e71cc1fa38"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gentleman'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('woold')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "__t_0RTdbwtT",
        "outputId": "d98fe60f-d878-43b7-8525-1c8f1c1744a9"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'would'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('heevy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DGPii9FYcqDt",
        "outputId": "a07e5a05-0e90-45ac-8fb3-388f5594b95f"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'heavy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correction('thrrwn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bpi1qEFjcxyh",
        "outputId": "ab04cedc-2819-4001-c8ae-aa7a2a47ffbd"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thrown'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix here\n",
        "#You can manually enter the values in your confusion matrix obtained in a 26x26 2D array and print the values.\n",
        "import numpy as np\n",
        "matrix = np.zeros ((26, 26))\n",
        "matrix[0][4]=matrix[0][4]+1\n",
        "matrix[14][20]=matrix[14][20]+1\n",
        "matrix[18][20]=matrix[18][20]+1\n",
        "matrix[0][2]=matrix[0][2]+1\n",
        "matrix[0][8]=matrix[0][8]+1\n",
        "matrix[17][0]=matrix[17][0]+1\n",
        "matrix[0][4]=matrix[0][4]+1\n",
        "matrix[14][20]=matrix[14][20]+1\n",
        "matrix[4][0]=matrix[4][0]+1\n",
        "matrix[17][14]=matrix[17][14]+1\n",
        "matrix"
      ],
      "metadata": {
        "id": "auxyI6UCdCTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6133e47-8fd5-47a8-fd52-34c899f3cc15"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 2., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 7 (10 points)\n",
        "Compare the Peter Norvig spelling correction method with that of the Noisy Channel method. Provide your observations in detail with examples."
      ],
      "metadata": {
        "id": "4fWEOEgqzVge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "***\n",
        "In  Petr Norvig Spelling Correction we may generate/use the confusion matrix. In Noisy Channel Method usually a model is trained but we do not train a model in Petr Norvig Spelling Correction. Petr Norvig Spelling Correction is much simpler to execute as compared to Noisy Channel Method.We have seen Petr Norvig in TASK 5 & 6 and we get the correct result for example: \"spaaking\"-->\"speaking\"."
      ],
      "metadata": {
        "id": "Ue87o1ZVzi4a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYpAfTKD9Kg1"
      },
      "source": [
        "# Task 8 (Bonus)\n",
        "### Implement spelling correction using Noisy Channel. You can follow any code. You can also use the spellchecker implementation here (not the statistical method) :https://medium.com/mlearning-ai/build-spell-checking-models-for-any-language-in-python-aa4489df0a5f"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install enchant --fix-missing\n",
        "!apt install -qq enchant\n",
        "!pip install pyenchantimport enchant\n",
        "import numpy as np\n",
        "import csv\n",
        "import math, collections\n",
        "import pandas as pd\n",
        "import re\n",
        "import itertools\n",
        "from nltk import tokenize\n",
        "import nltk.data\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "class Sentence_Corrector :\n",
        "    def __init__(self, training_file) :\n",
        "        self.laplaceUnigramCounts = collections.defaultdict(lambda: 0)\n",
        "        self.laplaceBigramCounts = collections.defaultdict(lambda: 0)\n",
        "        self.total = 0\n",
        "        self.sentences = []\n",
        "        self.importantKeywords = set()\n",
        "        #self.d = enchant.Dict(\"en_US\")\n",
        "        self.tokenize_file(training_file)\n",
        "        self.train()\n",
        "\n",
        "    def tokenize_file(self, file) :\n",
        "        # \"\"\"\n",
        "        #   Read the file, tokenize and build a list of sentences\n",
        "        # \"\"\"\n",
        "        tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "        #f = open(file)\n",
        "        content = file\n",
        "        for sentence in tokenizer.tokenize(content):\n",
        "            sentence_clean = [i.lower() for i in re.split('[^a-zA-Z]+', sentence) if i]\n",
        "            self.sentences.append(sentence_clean)\n",
        "    def train(self):\n",
        "        # \"\"\"\n",
        "        #   Train unigram and bigram\n",
        "        # \"\"\"\n",
        "        for sentence in self.sentences:\n",
        "            sentence.insert(0, '<s>')\n",
        "            sentence.append('</s>')\n",
        "            for i in range(len(sentence) - 1):\n",
        "                token1 = sentence[i]\n",
        "                token2 = sentence[i + 1]\n",
        "                self.laplaceUnigramCounts[token1] += 1\n",
        "                self.laplaceBigramCounts[(token1, token2)] += 1\n",
        "                self.total += 1\n",
        "            self.total += 1\n",
        "            self.laplaceUnigramCounts[sentence[-1]] += 1\n",
        "\n",
        "\n",
        "    def candidate_word(self, word):\n",
        "        # \"\"\"\n",
        "        # Generate similar word for a given word\n",
        "        # \"\"\"\n",
        "        suggests = []\n",
        "        for candidate in self.importantKeywords:\n",
        "            if candidate.startswith(word):\n",
        "                suggests.append(candidate)\n",
        "        suggests.append(word)\n",
        "\n",
        "        '''if len(suggests) == 1:\n",
        "            suggests = self.suggest(word)\n",
        "            suggests = [suggest.lower() for suggest in suggests][:4]\n",
        "            suggests.append(word)\n",
        "            suggests = list(set(suggests))\n",
        "\n",
        "        return suggests, len(suggests)'''\n",
        "    def candidate_sentence(self, sentence):\n",
        "        # \"\"\"\n",
        "        # Takes one sentence, and return all the possible sentences, and also return a dictionary of word : suggested number of words\n",
        "        # \"\"\"\n",
        "        candidate_sentences = []\n",
        "        words_count = {}\n",
        "        for word in sentence:\n",
        "            candidate_sentences.append(self.candidate_word(word)[0])\n",
        "            words_count[word] = self.candidate_word(word)[1]\n",
        "\n",
        "        candidate_sentences = list(itertools.product(*candidate_sentences))\n",
        "        return candidate_sentences, words_count\n",
        "\n",
        "    def correction_score(self, words_count, old_sentence, new_sentence) :\n",
        "        # \"\"\"\n",
        "        #   Take a old sentence and a new sentence, for each words in the new sentence, if it's same as the orginal sentence, assign 0.95 prob\n",
        "        #   If it's not same as original sentence, give 0.05 / (count(similarword) - 1)\n",
        "        # \"\"\"\n",
        "        score = 1\n",
        "        for i in xrange(len(new_sentence)) :\n",
        "            if new_sentence[i] in words_count :\n",
        "                score *= 0.95\n",
        "            else :\n",
        "                score *= (0.05 / (words_count[old_sentence[i]] - 1))\n",
        "        return math.log(score)\n",
        "    def score(self, sentence):\n",
        "        # \"\"\"\n",
        "        #     Takes a list of strings as argument and returns the log-probability of the\n",
        "        #     sentence using the stupid backoff language model.\n",
        "        #     Use laplace smoothing to avoid new words with 0 probability\n",
        "        # \"\"\"\n",
        "        score = 0.0\n",
        "        for i in range(len(sentence) - 1):\n",
        "            if self.laplaceBigramCounts[(sentence[i],sentence[i + 1])] > 0:\n",
        "                score += math.log(self.laplaceBigramCounts[(sentence[i],sentence[i + 1])])\n",
        "                score -= math.log(self.laplaceUnigramCounts[sentence[i]])\n",
        "            else:\n",
        "                score += (math.log(self.laplaceUnigramCounts[sentence[i + 1]] + 1) + math.log(0.4))\n",
        "                score -= math.log(self.total + len(self.laplaceUnigramCounts))\n",
        "        return score\n",
        "\n",
        "    def return_best_sentence(self, old_sentence) :\n",
        "        # \"\"\"\n",
        "        #   Generate all candiate sentences and\n",
        "        #   Calculate the prob of each one and return the one with highest probability\n",
        "        #   Probability involves two part 1. correct probability and 2. language model prob\n",
        "        #   correct prob : p(c | w)\n",
        "        #   language model prob : use stupid backoff algorithm\n",
        "        # \"\"\"\n",
        "        bestScore = float('-inf')\n",
        "        bestSentence = []\n",
        "        old_sentence = [word.lower() for word in old_sentence.split()]\n",
        "        sentences, word_count = self.candidate_sentence(old_sentence)\n",
        "        for new_sentence in sentences:\n",
        "            new_sentence = list(new_sentence)\n",
        "            score = self.correction_score(word_count, new_sentence, old_sentence)\n",
        "            new_sentence.insert(0, '<s>')\n",
        "            new_sentence.append('</s>')\n",
        "            score += self.score(new_sentence)\n",
        "            if score >= bestScore:\n",
        "                bestScore = score\n",
        "                bestSentence = new_sentence\n",
        "        bestSentence = ' '.join(bestSentence[1:-1])\n",
        "        return bestSentence, bestScore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJj3ZrTlsLXc",
        "outputId": "d83e67cd-73de-46e4-a764-8a080f22155d"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 14.2 kB/88.7 kB 16%] [Connected to cloud.\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 20.0 kB/88.7 kB 22%] [Connected to cloud.\u001b[0m\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 20.0 kB/88.7 kB 22%] [Waiting for headers\u001b[0m\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [2 InRelease gpgv 242 kB] [4 InRelease 14.2 kB/88.7 kB 16%] [1 InRelease 20.\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 242 kB] [4 InRelease 46.0 kB/88.7 kB 52%] [Waiting for hea\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Waiti\u001b[0m\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "\u001b[33m\r0% [2 InRelease gpgv 242 kB] [5 InRelease 8,393 B/83.3 kB 10%] [Waiting for hea\u001b[0m\u001b[33m\r                                                                               \r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                        \rHit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 261 kB in 2s (134 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "27 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "enchant is already the newest version (1.6.0-11.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n",
            "enchant is already the newest version (1.6.0-11.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyenchantimport (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pyenchantimport\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task8 = \"To Sherlock Holmes she is always the woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirable things for the observer--excellent for drawing the veil from men's motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\"\n",
        "corrector = Sentence_Corrector(task8)\n",
        "corrector.return_best_sentence('this is wron spallin word')\n",
        "corrector.return_best_sentence('aoccdrning to a resarch at cmabridge university')\n",
        "corrector.return_best_sentence('it does not mttaer in waht oredr the ltteers')\n",
        "corrector.return_best_sentence('the olny important tihng is taht')\n",
        "corrector.return_best_sentence('Can they leav him my messages')\n",
        "corrector.return_best_sentence('This used to belong to thew queen')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "myqz6ck8s_gA",
        "outputId": "1d329cb0-40f3-485f-a7bb-16a25d8551d4"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-2670945766bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtask8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"To Sherlock Holmes she is always the woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirable things for the observer--excellent for drawing the veil from men's motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorrector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentence_Corrector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorrector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_best_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'this is wron spallin word'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcorrector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_best_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aoccdrning to a resarch at cmabridge university'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorrector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_best_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'it does not mttaer in waht oredr the ltteers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-126-e6a3cfb21c9c>\u001b[0m in \u001b[0;36mreturn_best_sentence\u001b[0;34m(self, old_sentence)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mbestSentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mold_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mold_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnew_sentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mnew_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-126-e6a3cfb21c9c>\u001b[0m in \u001b[0;36mcandidate_sentence\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mwords_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mcandidate_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mwords_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}